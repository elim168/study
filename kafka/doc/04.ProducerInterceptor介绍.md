# ProducerInterceptor介绍

`org.apache.kafka.clients.producer.ProducerInterceptor`可以用来对Producer与Kafka服务器进行交互时进行拦截。它是一个接口，定义如下。

```java
/**
 * A plugin interface that allows you to intercept (and possibly mutate) the records received by the producer before
 * they are published to the Kafka cluster.
 * <p>
 * This class will get producer config properties via <code>configure()</code> method, including clientId assigned
 * by KafkaProducer if not specified in the producer config. The interceptor implementation needs to be aware that it will be
 * sharing producer config namespace with other interceptors and serializers, and ensure that there are no conflicts.
 * <p>
 * Exceptions thrown by ProducerInterceptor methods will be caught, logged, but not propagated further. As a result, if
 * the user configures the interceptor with the wrong key and value type parameters, the producer will not throw an exception,
 * just log the errors.
 * <p>
 * ProducerInterceptor callbacks may be called from multiple threads. Interceptor implementation must ensure thread-safety, if needed.
 * <p>
 * Implement {@link org.apache.kafka.common.ClusterResourceListener} to receive cluster metadata once it's available. Please see the class documentation for ClusterResourceListener for more information.
 */
public interface ProducerInterceptor<K, V> extends Configurable {
    /**
     * This is called from {@link org.apache.kafka.clients.producer.KafkaProducer#send(ProducerRecord)} and
     * {@link org.apache.kafka.clients.producer.KafkaProducer#send(ProducerRecord, Callback)} methods, before key and value
     * get serialized and partition is assigned (if partition is not specified in ProducerRecord).
     * <p>
     * This method is allowed to modify the record, in which case, the new record will be returned. The implication of modifying
     * key/value is that partition assignment (if not specified in ProducerRecord) will be done based on modified key/value,
     * not key/value from the client. Consequently, key and value transformation done in onSend() needs to be consistent:
     * same key and value should mutate to the same (modified) key and value. Otherwise, log compaction would not work
     * as expected.
     * <p>
     * Similarly, it is up to interceptor implementation to ensure that correct topic/partition is returned in ProducerRecord.
     * Most often, it should be the same topic/partition from 'record'.
     * <p>
     * Any exception thrown by this method will be caught by the caller and logged, but not propagated further.
     * <p>
     * Since the producer may run multiple interceptors, a particular interceptor's onSend() callback will be called in the order
     * specified by {@link org.apache.kafka.clients.producer.ProducerConfig#INTERCEPTOR_CLASSES_CONFIG}. The first interceptor
     * in the list gets the record passed from the client, the following interceptor will be passed the record returned by the
     * previous interceptor, and so on. Since interceptors are allowed to modify records, interceptors may potentially get
     * the record already modified by other interceptors. However, building a pipeline of mutable interceptors that depend on the output
     * of the previous interceptor is discouraged, because of potential side-effects caused by interceptors potentially failing to
     * modify the record and throwing an exception. If one of the interceptors in the list throws an exception from onSend(), the exception
     * is caught, logged, and the next interceptor is called with the record returned by the last successful interceptor in the list,
     * or otherwise the client.
     *
     * @param record the record from client or the record returned by the previous interceptor in the chain of interceptors.
     * @return producer record to send to topic/partition
     */
    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);

    /**
     * This method is called when the record sent to the server has been acknowledged, or when sending the record fails before
     * it gets sent to the server.
     * <p>
     * This method is generally called just before the user callback is called, and in additional cases when <code>KafkaProducer.send()</code>
     * throws an exception.
     * <p>
     * Any exception thrown by this method will be ignored by the caller.
     * <p>
     * This method will generally execute in the background I/O thread, so the implementation should be reasonably fast.
     * Otherwise, sending of messages from other threads could be delayed.
     *
     * @param metadata The metadata for the record that was sent (i.e. the partition and offset).
     *                 If an error occurred, metadata will contain only valid topic and maybe
     *                 partition. If partition is not given in ProducerRecord and an error occurs
     *                 before partition gets assigned, then partition will be set to RecordMetadata.NO_PARTITION.
     *                 The metadata may be null if the client passed null record to
     *                 {@link org.apache.kafka.clients.producer.KafkaProducer#send(ProducerRecord)}.
     * @param exception The exception thrown during processing of this record. Null if no error occurred.
     */
    public void onAcknowledgement(RecordMetadata metadata, Exception exception);

    /**
     * This is called when interceptor is closed
     */
    public void close();
}
```

ProducerInterceptor的父接口Configurable中定义了一个`configure(Map<String, ?> configs)`方法，加上它自己的三个方法，一共是四个方法。它们的作用如下。

* onSend：用于消息发送到Kafka服务器前进行相应的处理。
* onAcknowledgement：用于对消息发送的结果进行相应的处理。它可能是在消息发送到Kafka服务器之前就失败了，也可能是来自于Kafka服务器的响应。
* close：用于在Producer关闭时进行相应的处理。
* configure：通过它可以获取Producer的其它配置信息，然后可以根据需要把它们保存起来，在其它方法中使用。

如下就是一个自定义的ProducerInterceptor。

```java
public class MyProducerInterceptor implements ProducerInterceptor<String, String> {
  @Override
  public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
    System.out.println("进行消息发送拦截：" + record.topic() + "----" + record.key() + "----" + record.value());
    record.headers().add("header1", "header1-value".getBytes());
    return record;
  }

  @Override
  public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
    if (exception == null) {
      System.out.println("收到响应，发送消息成功：" + metadata);
    } else {
      System.out.println("收到响应，发送消息失败：" + exception.getMessage());
    }
  }

  @Override
  public void close() {
    System.out.println("Producer关闭时调用");
  }

  @Override
  public void configure(Map<String, ?> configs) {
    System.out.println("已经配置好的配置信息有：" + configs);
  }
}
```

然后如果某个Producer需要使用它，就在Producer的配置参数中通过`interceptor.classes`指定需要应用的ProducerInterceptor接口的实现类。比如下面这样。

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("acks", "all");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("interceptor.classes", "com.elim.study.kafka.producer.interceptor.MyProducerInterceptor");
Producer<String, String> producer = new KafkaProducer<>(props);
```

ProducerInterceptor也可以同时指定多个，当需要指定多个时，配置信息就不能使用Properties了，应该使用更基础的Map。这时候应该像如下这样使用。

```java
Map<String, Object> configs = new HashMap<>();
configs.put("bootstrap.servers", "localhost:9092");
configs.put("acks", "all");
configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
List<String> interceptors = new ArrayList<>();
interceptors.add("com.elim.study.kafka.producer.interceptor.MyProducerInterceptor");
interceptors.add("com.elim.study.kafka.producer.interceptor.MyProducerInterceptor2");
configs.put("interceptor.classes", interceptors);
Producer<String, String> producer = new KafkaProducer<>(configs);
```

（注：本文是基于Kafka2.3.0所写）