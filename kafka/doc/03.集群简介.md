# 集群简介

同一Zookeeper集群上注册的Kafka服务器将组成一个Kafka集群。Kafka集群中的每一个节点的`broker.id`都必须是唯一的，默认是0，如果有三个节点可以把它们分别指定0/1/2。Kafka默认是监听在9092端口的，如果手上没有多台机器，需要在一台机器上验证Kafka集群，可以修改配置文件中监听的端口，还需要修改日志目录，以免冲突。在本地验证Kafka集群时可以把config目录下的server.properties复制两份，分别命名为server1.properties和server2.properties。然后它们的下面三项信息配置分别如下。

server.properties

```properties
broker.id=0
listeners=PLAINTEXT://:9092
log.dirs=/tmp/kafka-logs
```

server1.properties

```properties
broker.id=1
listeners=PLAINTEXT://:9093
log.dirs=/tmp/kafka-logs1
```

server2.properties

```properties
broker.id=2
listeners=PLAINTEXT://:9094
log.dirs=/tmp/kafka-logs2
```

然后通过`bin/kafka-server-start.sh config/server.properties`依次启动3个Kafka服务，每次都使用不同的配置文件（这是假设你在本机已经启动了Zookeeper，且监听在默认的2181端口）。这样就启动了3个Kafka服务器，它们分别监听在端口9092/9093/9094，组成了一个集群。然后使用下面的命令可以创建一个名为`topic-c1`的Topic，该Topic有3个副本、3个分区。

```text
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 3 --topic topic-c1
```

> 与Kafka集群的服务器打交道时只需要指定其中的一部分Kafka服务器地址即可。

然后可以通过如下指令查看我们刚刚创建的Topic的描述信息。

```text
bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic topic-c1
```

你会看到如下信息。第一行是该Topic的一个概述信息。然后之后的每一行列出的是其中的一个分区的信息。拿第二行来说，它对应的是0号分区，它的主节点是`broker.id=1`的Kafka服务器，副本分别是`broker.id`为0/1/2的服务器。分区1和2是类似的。

```text
Topic:topic-c1	PartitionCount:3	ReplicationFactor:3	Configs:segment.bytes=1073741824
	Topic: topic-c1	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
	Topic: topic-c1	Partition: 1	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2
	Topic: topic-c1	Partition: 2	Leader: 2	Replicas: 2,0,1	Isr: 2,0,1
```

然后我们来验证一下收发消息，通过如下命令启动一个消费者，它指定的Kafka地址是`localhost:9094`。

```text
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 --topic topic-c1 --from-beginning
```

然后通过如下命令启动一个生产者进行消息发送，它指定的Kafka地址是`localhost:9093`。每行是一条消息，发送完后按`Ctrl+C`结束。

```text
bin/kafka-console-producer.sh --broker-list localhost:9093 --topic topic-c1
```

发送完后你会在刚刚启动的消费者界面看到它收到了你发送的消息。这说明我们的集群生效了，因为消费者指定的地址是`localhost:9094`，而生产者发送到的地址是`localhost:9093`。

接下来我们把`broker.id=2`的Kafka服务器停掉，接着我们再运行`bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic topic-c1`来看一下topic-c1的描述信息。可以看到原本分区2的主节点是`broker.id=2`的Kafka服务器，现在变成了`broker.id=0`的服务器。每个分区的副本都还是一样的，但是它们的可用副本都编程了`broker.id`为0和1的服务器。

```text
Topic:topic-c1	PartitionCount:3	ReplicationFactor:3	Configs:segment.bytes=1073741824
	Topic: topic-c1	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,0
	Topic: topic-c1	Partition: 1	Leader: 0	Replicas: 0,1,2	Isr: 0,1
	Topic: topic-c1	Partition: 2	Leader: 0	Replicas: 2,0,1	Isr: 0,1
```

我们刚刚停掉的是`broker.id=2`的Kafka服务，我们知道该服务监听的是9094端口，我们刚刚启动的消费者指定的地址也是监听9094端口的Kafka地址。这个时候如果你继续用刚刚的生产者发送一条消息，你会发现之前启动的消费者还是可以收到消息。这是因为消费者通过集群中的一个服务`localhost:9094`拿到了集群中所有机器的信息，当一个节点挂掉后，原本属于该节点的分区信息将分配给其它节点，客户端也可以从其它节点继续进行消费。

（注：本文是基于Kafka2.3.0所写）